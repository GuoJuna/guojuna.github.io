(window.webpackJsonp=window.webpackJsonp||[]).push([[128],{603:function(a,t,e){"use strict";e.r(t);var i=e(0),v=Object(i.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"主要功能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#主要功能"}},[a._v("#")]),a._v(" 主要功能")]),a._v(" "),t("ul",[t("li",[a._v("解耦")]),a._v(" "),t("li",[a._v("异步")]),a._v(" "),t("li",[a._v("削峰")])]),a._v(" "),t("h2",{attrs:{id:"mq优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mq优缺点"}},[a._v("#")]),a._v(" MQ优缺点")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gj-blog.oss-cn-hangzhou.aliyuncs.com/blog-img/2020/09/20200910143522.png",alt:"image-20200910143515480"}})]),a._v(" "),t("h2",{attrs:{id:"rabbitmq-的高可用性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq-的高可用性"}},[a._v("#")]),a._v(" RabbitMQ 的高可用性")]),a._v(" "),t("p",[a._v("RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。")]),a._v(" "),t("p",[a._v("单机模式\n单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的😄，没人生产用单机模式。")]),a._v(" "),t("p",[a._v("普通集群模式（无高可用性）\n普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。")]),a._v(" "),t("p",[a._v("镜像集群模式（高可用性）\n这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。")]),a._v(" "),t("h2",{attrs:{id:"如何保证消息消费的幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证消息消费的幂等性"}},[a._v("#")]),a._v(" 如何保证消息消费的幂等性？")]),a._v(" "),t("ol",[t("li",[a._v("比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。")]),a._v(" "),t("li",[a._v("比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。")]),a._v(" "),t("li",[a._v("比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。")]),a._v(" "),t("li",[a._v("比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。")])]),a._v(" "),t("h2",{attrs:{id:"如何保证消息的可靠性传输"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证消息的可靠性传输"}},[a._v("#")]),a._v(" 如何保证消息的可靠性传输？")]),a._v(" "),t("p",[a._v("数据的丢失问题，可能出现在生产者、MQ、消费者中")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("生产者弄丢了数据"),t("br"),a._v("\n可以用confirm 机制,要确保说写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。")])]),a._v(" "),t("li",[t("p",[a._v("RabbitMQ 弄丢了数据\n就是 RabbitMQ 自己弄丢了数据，这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。")])])]),a._v(" "),t("p",[a._v("设置持久化有两个步骤：")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("创建 queue 的时候将其设置为持久化\n这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。")])]),a._v(" "),t("li",[t("p",[a._v("第二个是发送消息的时候将消息的 deliveryMode 设置为 2\n就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。")])]),a._v(" "),t("li",[t("p",[a._v("消费端弄丢了数据\n这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。")])])]),a._v(" "),t("h2",{attrs:{id:"如何保证消息的顺序性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证消息的顺序性"}},[a._v("#")]),a._v(" 如何保证消息的顺序性？")]),a._v(" "),t("p",[a._v("拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理")]),a._v(" "),t("h2",{attrs:{id:"如何解决消息队列的延时以及过期失效问题-消息队列满了以后该怎么处理-有几百万消息持续积压几小时-说说怎么解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何解决消息队列的延时以及过期失效问题-消息队列满了以后该怎么处理-有几百万消息持续积压几小时-说说怎么解决"}},[a._v("#")]),a._v(" 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？")])])}),[],!1,null,null,null);t.default=v.exports}}]);